{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport scipy\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntf_vectorizer = TfidfVectorizer(min_df=3,  max_features=3000, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{3,}',\n            ngram_range=(1, 3),\n            stop_words = 'english')\n\n\ncsv_list = os.listdir(\"../input/vitube\")\ncsv_list = {x.replace(\"vitube_table_\", \"\").replace(\".csv\", \"\"): \"../input/vitube/\" + x for x in csv_list}\nactivity_df = pd.read_csv(csv_list[\"activities\"])\nuser_df = pd.read_csv(csv_list[\"users\"])\ncategory_df = pd.read_csv(csv_list[\"categories\"])\nhistory_df = pd.read_csv(csv_list[\"watch_histories\"])\nhistory_df.drop(columns=[\"liked\", \"disliked\"], inplace=True)\n\nvideo_df = pd.read_csv(csv_list[\"videos\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"video_df[\"description\"].fillna(\"\", inplace=True)\nvideo_df[\"description\"] = video_df[\"description\"].apply(lambda x: re.sub(r\"http\\S+\", \"\", x or \"\"))\n\nfeatures = [\"id\", \"duration\", \"category_id\", \"comments\", \"name\", \"description\"]\nvid_info = video_df[features]\nvid_info.columns = [\"video_id\"] + features[1:] \nhistory_df = history_df.merge(vid_info, on=\"video_id\", how=\"left\")\nhistory_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"useful_feats = [\"likes\", \"dislikes\", \"views\", \"duration\",\n               \"category_id\", \"comments\", \"name\", \"description\",\n               ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def consine_sim(x1, x2):\n    return 1 - scipy.spatial.distance.cosine(x1, x2)\ndef get_user_activities(user_id, action=\"like\"):\n    return activity_df[(activity_df[\"user_id\"] == user_id) & (activity_df[\"type\"] == action)]\n\ndef get_last_video(user_id, n=100):\n    user_filter = history_df[\"user_id\"] == user_id\n    videos = history_df[user_filter]\n    return videos\n\ndef gen_video_feature(videos):\n    \"\"\"Video should be df\"\"\"\n    return videos[useful_feats]\n\ndef concat_feat(feats, mat):\n    feats.fillna(0, inplace=True)\n    vec = feats.values\n    combined = np.concatenate([vec, mat.A], axis=1)\n    row_max = combined.max(axis=0)\n#     print(row_max.shape, combined.shape, row_max)\n    return combined / row_max[np.newaxis, :]\n\nfeats = video_df[useful_feats]\nfeats[\"text\"] = feats[\"description\"] + \" \" + feats[\"name\"]\nfeats[\"text\"].fillna(\"\", inplace=True)\nmat = tf_vectorizer.fit_transform(feats[\"text\"])\n\nfeats.drop(columns=[\"name\", \"description\", \"text\"], inplace=True)\nvectors = concat_feat(feats, mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def recommend_for(video_id, vectors):\n    idx = np.where(video_df[\"id\"] == video_id)[0][0]\n    most_similar_with = [\n        (i, consine_sim(vectors[idx], vectors[i])) for i in range(len(feats))\n    ]\n    \n    bests = sorted(most_similar_with, reverse=True, key=lambda x: x[1])[0:11]\n    \n    return [\n        (video_df.iloc[best[0]][\"id\"], video_df.iloc[best[0]][\"name\"],best[1]) for best in bests\n    ]\n\nrecommended = recommend_for(71, vectors)\nframe = pd.DataFrame(recommended)\nframe.columns = [\"video_id\", \"video\", \"score\"]\nframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.where(mat.A[15] > 0), np.where(vectors[15][6:] > 0)\n# video_df[video_df[\"id\"] == 5330]\nvectors.shape\n# tf_vectorizer.get_feature_names()[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nlen(sklearn.feature_extraction.text.ENGLISH_STOP_WORDS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save(\"save\", vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!du -sh save.npy","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}